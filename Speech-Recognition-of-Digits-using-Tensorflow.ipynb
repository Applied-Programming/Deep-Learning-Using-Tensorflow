{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech Recognition of Digits using Tensorflow\n",
    "<hr>\n",
    "\n",
    "Here we're going to build our own deep neural network that learns to recognize spoken numbers. We're going to:\n",
    "1. Download a labelled data set of people saying numbers,\n",
    "2. Then build a neural network\n",
    "3. Train on that data\n",
    "4. Finally test it out see if we can recognize other spoken numbers\n",
    "\n",
    "This example demonstrates a Tensorflow implementation of  Speech Recognition.\n",
    "We build an LSTM recurrent neural network using the TFLearn high level Tensorflow-based library to train\n",
    "on a labeled dataset of spoken digits. Then we test it on spoken digits. \n",
    "\n",
    "Dependencies\n",
    "============\n",
    "1. tensorflow  (https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html)\n",
    "2. tflearn (http://tflearn.org/)\n",
    "3. future\n",
    "\n",
    "Use [pip](https://pypi.python.org/pypi/pip) to install any missing dependencies\n",
    "\n",
    "Let's dive into our code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! python27\n",
    "# demo.py\n",
    "from __future__ import division, print_function, absolute_import\n",
    "import tflearn\n",
    "import speech_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import TFlearn. [TFLearn](http://tflearn.org/) is a high-level library built on top of TensorFlow that is easier to read and great for quick prototyping.\n",
    "\n",
    "Our other import is a helper class called `speech data` which will help fetch data from the web and format it for us.\n",
    "You can get it from [here](https://github.com/Aniruddha-Tapas/Speech-Recognition-of-Digits-using-Tensorflow/blob/master/speech_data.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our libraries let's define are hyper parameters or tuning knobs. We have three of them:\n",
    "1. learning rate :  learning rate is what we applied to this weight updating process. The greater the learning rate, the faster our network trains; the lower the learning rate the more accurate our network predicts. So it represents a trade-off between time and accuracy.\n",
    "2. training_iters : defines how many steps we want to train - 300,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "training_iters = 300000  # steps\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have our hyperparameters. Now we can fetch our data. This is where we'll use our helper class `speech_data.py`, specifically its `mfcc_batch_generator` function. This function will download a set of wave files. Each wave file is a recording of a different spoken digit like and each is labeled with a written digits. It will return the list of labeled speech files\n",
    "as a batch. Then we can split our batch into training and testing data with pythons built-in `next` function. We will use\n",
    "the same data for testing for simplicity so it'll be able to recognize the speaker we trained it on but not other\n",
    "speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = 20  # mfcc features\n",
    "height = 80  # (max) length of utterance\n",
    "classes = 10  # digits\n",
    "\n",
    "batch = word_batch = speech_data.mfcc_batch_generator(batch_size)\n",
    "X, Y = next(batch)\n",
    "trainX, trainY = X, Y\n",
    "testX, testY = X, Y #overfit for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training and testing data it's time to make our neural network. Since spoken words are a sequence of sound waves, we want to use a recurrent neural network since they're capable of processing sequences. So we'll initialize our net by calling tflearn's `input_data` function. This initial input layer will be the gateway that data is fed into the network and the\n",
    "parameters will help define the shape of our input_Data or as TensoFlow calls it - our input tensor. A 'tensor' is a fancy\n",
    "word for a multi-dimensional array of data. Our two parameters will be the width and height. The width is the number of features that are extracted from our utterances in our speech_data helper class and the height is the max length of each utterances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network building\n",
    "net = tflearn.input_data([None, width, height])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next layer we use TFlearn's **LSTM** or Long Short Term Memory function. In a recurrent net the output data's contents is influenced not only by the input we just put in but by the entire history of inputs to our recurring loop. LSTMs are the type of recurrent net that can remember everything that is fed and because of that they outperform regular recurrent nets consistently. \n",
    "\n",
    "We'll use our previous layer as our first parameter since we are feeding tensors from one layer to the next. Then the number of neurons. There's not really a rule for knowing how many neurons using a layer; too few will lead to bad predictions and too many will overfit to our training data, meaning it will not generalize well. Let's pick 128. And then our dropout value which says how much dropout do we want. Dropout helps prevent overfitting by randomly turning off some neurons during training, so the data is forced to find new paths between layers allowing for more generalized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.lstm(net, 128, dropout=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our next layer will be fully connected meaning every neuron in the previous layer will be connected to its neurons\n",
    "and our number of classes are ten as we are only recognizing 10 digits. We'll set the activation function to `softmax` which\n",
    "will convert numerical data into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.fully_connected(net, classes, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we'll create our output layer as a regression which will output a single predicted number for our utterance. We're using the popular Adam optimizer to minimize our categorical cross-entropy loss function over time so we get a more accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = tflearn.regression(net, optimizer='adam', learning_rate=learning_rate, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize our network using TFlearn's DNN (Deep Neural Net) function and tensor_board verbose to 0 which\n",
    "means we want a detailed visualization. We'll initialize our training loop then fit our model to the training and testing\n",
    "data for ten epochs with our specified batch size. Then will predict a spoken digits value from our training data. We also make sure to save our model for later use and print our result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "### add this \"fix\" for tensorflow version errors\n",
    "col = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "for x in col:\n",
    "    tf.add_to_collection(tf.GraphKeys.VARIABLES, x ) \n",
    "\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "while 1: #training_iters\n",
    "  model.fit(trainX, trainY, n_epoch=10, validation_set=(testX, testY), show_metric=True,\n",
    "          batch_size=batch_size)\n",
    "  _y=model.predict(X)\n",
    "model.save(\"tflearn.lstm.model\")\n",
    "print (_y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFlearn has a nice log of important training variables built-in just from running the fit function; so we don't have to specify\n",
    "what things to print. After its done training you will predict the digits and if we wanted to we could just record\n",
    "yourself saying a number and place it in the directory then predict that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "\n",
    "So to break it down LSTM neural networks are used in state-of-the-art speech recognition. We can use [TFlearn](http://tflearn.org/) to quickly build and train a deep neural network to recognize\n",
    "speech. And good hyper parameters like the learning rate are those that are balanced between trade-offs like time\n",
    "and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entire `demo.py` script: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tflearn\n",
    "import speech_data\n",
    "import tensorflow as tf\n",
    "\n",
    "learning_rate = 0.0001\n",
    "training_iters = 300000  # steps\n",
    "batch_size = 64\n",
    "\n",
    "width = 20  # mfcc features\n",
    "height = 80  # (max) length of utterance\n",
    "classes = 10  # digits\n",
    "\n",
    "batch = word_batch = speech_data.mfcc_batch_generator(batch_size)\n",
    "X, Y = next(batch)\n",
    "trainX, trainY = X, Y\n",
    "testX, testY = X, Y #overfit for now\n",
    "\n",
    "# Network building\n",
    "net = tflearn.input_data([None, width, height])\n",
    "net = tflearn.lstm(net, 128, dropout=0.8)\n",
    "net = tflearn.fully_connected(net, classes, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=learning_rate, loss='categorical_crossentropy')\n",
    "# Training\n",
    "\n",
    "### add this \"fix\" for tensorflow version errors\n",
    "col = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "for x in col:\n",
    "    tf.add_to_collection(tf.GraphKeys.VARIABLES, x ) \n",
    "\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "while 1: #training_iters\n",
    "  model.fit(trainX, trainY, n_epoch=10, validation_set=(testX, testY), show_metric=True,\n",
    "          batch_size=batch_size)\n",
    "  _y=model.predict(X)\n",
    "model.save(\"tflearn.lstm.model\")\n",
    "print (_y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run this code in terminal:\n",
    "* This downloads the dataset into the 'data' folder and initiates the training process.\n",
    "* It will take a couple hours to train fully.\n",
    "* You can then test the trained model on your own .wav samples of spoken digits.\n",
    "\n",
    "## You can download the entire code from [here](https://github.com/Aniruddha-Tapas/Speech-Recognition-of-Digits-using-Tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
